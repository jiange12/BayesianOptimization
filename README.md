Bayesian Optimization Framework (Optuna + CSV-Defined Search Spaces)

This repository provides a lightweight, fully generic Bayesian hyperparameter optimization framework built on Optuna.
It lets you:

Define your hyperparameter search space in a simple CSV file

Plug in any Python function (run_model) that returns a scalar loss

Run Bayesian optimization (TPE sampler, optionally multivariate)

Automatically log all trials to CSV

Use the included toy and PyTorch examples to get started quickly

The design goal is to make hyperparameter tuning transparent, reproducible, and model-agnostic.

Quick Start
1. Install dependencies
pip install optuna torch numpy pandas

2. Define your search space (CSV)

Create a file such as param_space.csv:

name;type;low;high;log;choices;default
lr;float;1e-5;1e-2;True;;
weight_decay;float;1e-6;1e-2;True;;
hidden_size;int;16;256;False;;
dropout;float;0.0;0.5;False;;
optimizer;categorical;;;;"adam,adamw,sgd";
gamma;float;0.90;0.999;False;;


Each row declares one hyperparameter.
The framework parses this and automatically uses the appropriate Optuna sampling method.

3. Write your black-box function (run_model)

You can provide any function as long as it returns a numeric loss:

def run_model(**params):
    # Train a model, evaluate it, or run *anything*
    loss = ...
    return loss


Examples included in the repo:

toy_black_box.py — deterministic toy objective

test_black_box.py — simple PyTorch regression model

4. Run optimization

In your script:

from general_bayes_opt import bayesian_optimize
from toy_black_box import run_model

study, df = bayesian_optimize(
    run_model,
    param_csv_path="param_space.csv",
    n_trials=100,
)


This will:

Read the CSV-defined search space

Create a TPE-based Optuna study

Suggest parameter sets

Evaluate run_model

Log every trial into a CSV (default: bayes_trials.csv)

Return:

study: the Optuna study object

df: a pandas DataFrame containing all trial results

5. Inspect results
print("Best params:", study.best_params)
print("Best loss:", study.best_value)

Repository Structure
.
├── general_bayes_opt.py     # Core Bayesian optimization engine
├── main.py                  # Example entry point
├── toy_black_box.py         # Fast deterministic objective
├── test_black_box.py        # PyTorch example black box
├── param_space.csv          # Example search space definition
├── bayes_trials.csv         # Trial history generated by toy example
├── trial_history.csv        # Trial history for the PyTorch example

How It Works
1. CSV → Sampling Spec

general_bayes_opt.py reads your CSV and converts each row into one of:

trial.suggest_float

trial.suggest_int

trial.suggest_categorical

trial.suggest_bool

It automatically handles:

log-scaled sampling

lists of categorical values

default values

optional parameter overrides

2. Bayesian Optimization (Optuna TPE)

The optimizer uses a customizable TPE sampler:

Supports good_fraction to control the top-percentile considered "good"

Allows multivariate mode

Uses n_startup_trials before TPE engages

3. Logging

After each trial:

The full parameter set + loss are appended to a DataFrame

The DataFrame is written to a CSV on disk

This allows live monitoring, experiment reproducibility, and resumability

Example: Toy Optimization (default in main.py)

toy_black_box.py defines a deterministic loss centered around a “true” optimum.
Running optimization should rapidly rediscover those values.

This is a great sanity check for the optimizer pipeline.

Example: Real Model (PyTorch)

test_black_box.py demonstrates optimizing a small MLP on a synthetic regression task:

Optimizes architecture (hidden_size, dropout)

Optimizes optimizer choice and scheduler (optimizer, gamma)

Combines MSE and MAE into a single loss

Uncomment the relevant block in main.py to run it.

Parameters in the CSV
Column	Meaning
name	Hyperparameter name passed to your run_model
type	float, int, categorical, or bool
low / high	Range for numeric parameters
log	Whether to sample on a log scale
choices	For categorical parameters (comma-separated or Python list)
default	Optional fallback value

Missing fields are auto-filled with safe defaults.

Extending the Framework

You can:

Add new search spaces by editing the CSV

Replace run_model with your own training/prediction code

Customize TPE sampling behavior

Use Optuna’s advanced features (pruning, callbacks, etc.) by extending general_bayes_opt.py

Add support for new parameter types or constraints

Requirements

Python 3.8+

PyTorch (only for the PyTorch black-box example)

Optuna

Pandas

Numpy
